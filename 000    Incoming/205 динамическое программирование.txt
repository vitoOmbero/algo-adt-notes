Динамическое программирование


Динамическое программирование (ДП) – способ
решения сложных задач путём разбиения их на
более простые подзадачи.
Подход динамического программирования состоит в том, 
чтобы решить каждую подзадачу только один раз, 
сократив тем самым количество вычислений.
Термин «динамическое программирование» также встречается в
теории управления в смысле «динамической оптимизации». Основным
методом ДП является сведение общей задачи к ряду более простых
экстремальных задач.
Лит.: Беллман Р., Динамическое программирование, пер. с англ., М., 
1960.


Пример. Числа Фибоначчи. 

Можно вычислять рекурсивно:

Многие значения могут вычисляться несколько раз. Решение - сохранять результаты решения подзадач.
Этот подход называется кэшированием.

Пример. Вычисление рекуррентных функций нескольких аргументов

...

// Вычисление рекуррентного выражения от двух переменных.
int F( int x, int y )
{
vector<vector<int>> values( x + 1 );
for( int i = 0; i <= x; ++i ) {
values[i].resize( y + 1 );
values[i][0] = i; // F( x, 0 ) = x;
}
for( int i = 1; i <= y; ++i ) {
values[0][i] = 0; // F( 0, y ) = 0;
}
// Вычисляем по рядам.
for( int i = 0; i <= x; ++i ) {
for( int j = 0; j <= y; ++j ) {
values[i][j] = 3 * values[i – 1][j] –
2 * values[i][j – 1] * values[i][j – 1];
}
}
return value[x][y];
}


При вычисление рекуррентной функции F(x, y) можно было не хранить значения на всех рядах. ДЛя вычисления очередного ряда достаточно иметь значения предыдущего ряда.
ВАЖНАЯ оптимизация ДП: Запоминать только те значния, которые будут использоваться для последующих вычислений.

Для вычисления числа Фибоначчи Fi также достаточно хранить лишь два предыдущих значения: Fi-1 и Fi-2.

Принципы ДП:
1. Разбить задачу на подзадачи.
2. Кэшировать результаты решения подзадач.
3. Удалять более неиспользуемые результаты решения подзадач (опционально).

Два подхода динамического программирования:
1. Нисходящее динамическое программирование: задача разбивается
на подзадачи меньшего размера, они решаются и затем
комбинируются для решения исходной задачи. Используется
запоминание для решений часто встречающихся подзадач.
2. Восходящее динамическое программирование: все подзадачи, 
которые впоследствии понадобятся для решения исходной задачи
просчитываются заранее и затем используются для построения
решения исходной задачи.
Второй способ лучше нисходящего программирования в смысле
размера необходимого стека и количества вызова функций, но иногда
бывает нелегко заранее выяснить, решение каких подзадач нам
потребуется в дальнейшем.

Иногда бывает нелегко заранее выяснить, решение каких подзадач
нам потребуется в дальнейшем.
Пример./// ltktybt 
деление
целочисленное.
Восходящее динамическое программирование применить можно, но
будут вычислены все значения F от 1 до n. Сложно определить, для
каких k требуется вычислять F(k).

Нисходящее ДП позволит вычислить только те F(k), которые требуются, но рекурсивно.
Макс глубина рекурсии = log 3/2 (n)

// Вычисление рекуррентного выражения методом нисходящего ДП.
int F( int n )
{
std::vector<int> values( n, -1 );
values[0] = 1;
values[1] = 1;
return calcF( n, values );
}
// Рекурсивное вычисление с запоминанием.
int calcF( int n, std::vector<int>& values )
{
if( values[n] != -1 )
return values[n];
values[n] = calcF( n / 2, values ) + calcF( 2 * n / 3, values );
return values[n];
}


Наибольшая общая подпоследовательность


Последовательность X является подпоследовательностью
Y, если из Y можно удалить несколько элементов так, что
получится последовательность X.
Задача. Наибольшая общая подпоследовательность (англ. 
longest common subsequence, LCS) – задача поиска
последовательности, которая является
подпоследовательностью нескольких
последовательностей (обычно двух).
Элементами подпоследовательности могут быть числа, 
символы…
X = ABCAB,
Y = DCBA,
НОП( X, Y ) = BA, CA, CB.


Будем решать задачу нахождения наибольшей общей
подпоследовательности с помощью ДП.
Сведем задачу к подзадачам меньшего размера:


...

...

В каждой ячейке – длина наибольшей общей подстроки соответствующих 
начал строк.


f(n1, n2) - длина НОП.

Как восстановить саму подпоследовательность?
Можно хранить в каждой ячейке таблицы «направление»
перехода. Переход по диагонали означает, что очередной
символ присутствует в обоих последовательностях.
Начинаем проход от правого нижнего угла.
Идем по стрелкам, на каждый переход по диагонали
добавляем символ в начало строящейся
подпоследовательности.
«Направления» можно не хранить, а вычислять по
значениям в таблице.

ююю

Желтым выделены ячейки, лежащие на лучшем пути.
Переход по диагонали соответствует совпадению символа.



Расстояние Левенштейна

Расстояние Левенштейна (также редакционное
расстояние или дистанция редактирования) между
двумя строками – это минимальное количество
следующих операций:
• вставки одного символа,
• удаления одного символа,
• замены одного символа на другой,
необходимых для превращения одной строки в другую.
Впервые задачу упомянул в 1965 году советский математик
Владимир Иосифович Левенштейн при изучении
последовательностей 0-1.

Расстояние Левенштейна и его обобщения активно
применяется:
• для исправления ошибок в слове (в поисковых системах, 
базах данных, при вводе текста, при автоматическом
распознавании отсканированного текста или речи).
• для сравнения текстовых файлов утилитой diff и ей
подобными. Здесь роль «символов» играют строки, а
роль «строк» — файлы.
• в биоинформатике для
сравнения генов, хромосом и белков.

Будем вычислять расстояние Левенштейна с помощью
Динамического программирования.

....

пример.

ююю

// Вычисление расстояния Левенштейна.
int LevenshteinDistance( const string& s, int sLength, const string& t, 
int tLength )
{
// Крайние случаи.
if( sLength == 0 ) return tLength;
if( tLength == 0 ) return sLength;
// Проверим совпадение последних символов.
int cost = s[sLength - 1] == t[tLength - 1] ? 0 : 1;
// Вычисляем минимум.
return min( LevenshteinDistance( s, sLength - 1, t, tLength ) + 1,
LevenshteinDistance( s, sLength, t, tLength – 1 ) + 1,
LevenshteinDistance( s, sLength - 1, t, tLength – 1 ) + cost );
}




